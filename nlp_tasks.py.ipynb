{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-b15e74243503>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b15e74243503>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    The script will showcase the following tasks:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The script will showcase the following tasks:\n",
    "\n",
    "Sentence Sentiment Classification\n",
    "Named Entity Recognition\n",
    "Question Answering\n",
    "Text Summarization\n",
    "Fill-in-the-blank Tasks\n",
    "Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[sentencepiece]\n",
      "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m913.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (3.0.12)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers[sentencepiece])\n",
      "  Downloading huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (2020.11.13)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (2.25.1)\n",
      "Collecting safetensors>=0.4.1 (from transformers[sentencepiece])\n",
      "  Downloading safetensors-0.4.5-cp38-cp38-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers[sentencepiece])\n",
      "  Downloading tokenizers-0.19.1-cp38-cp38-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.8/site-packages (from transformers[sentencepiece]) (4.54.1)\n",
      "Collecting protobuf (from transformers[sentencepiece])\n",
      "  Downloading protobuf-5.28.1-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
      "  Downloading sentencepiece-0.2.0-cp38-cp38-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece])\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (4.8.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (1.26.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (2023.5.7)\n",
      "Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp38-cp38-macosx_10_12_x86_64.whl (392 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.9/392.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp38-cp38-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp38-cp38-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.28.1-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.7/414.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, safetensors, protobuf, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.3\n",
      "    Uninstalling fsspec-0.8.3:\n",
      "      Successfully uninstalled fsspec-0.8.3\n",
      "Successfully installed fsspec-2024.9.0 huggingface-hub-0.25.0 protobuf-5.28.1 safetensors-0.4.5 sentencepiece-0.2.0 tokenizers-0.19.1 transformers-4.44.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install 'transformers[sentencepiece]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 1: Sentence Sentiment Classification\n",
      "I had an absolutely amazing stay at this hotel. The rooms were impeccably clean,\n",
      "spacious, and beautifully decorated, with all the amenities I needed for a\n",
      "relaxing stay. The bed was incredibly comfortable, and the views from my room\n",
      "were stunning.!\n",
      "Sentiment: 5 stars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wrapper = textwrap.TextWrapper(width=80, break_long_words=False, break_on_hyphens=False)\n",
    "# Task 1: Classifying the sentiment of a hotel review\n",
    "sentence = \"I had an absolutely amazing stay at this hotel. The rooms were impeccably clean, spacious, and beautifully decorated, with all the amenities I needed for a relaxing stay. The bed was incredibly comfortable, and the views from my room were stunning.!\"\n",
    "print(\"\\nTask 1: Sentence Sentiment Classification\")\n",
    "classifier = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment', device=0)\n",
    "sentiment = classifier(sentence)\n",
    "print(wrapper.fill(sentence))\n",
    "print(f\"Sentiment: {sentiment[0]['label']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 2: Named Entity Recognition\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273cb4355a944e38b040edfc2e65ff87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='config.json'), FloatProgress(value=0.0, max=829.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc5e491ba8242de8d0a118ae2e92b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='model.safetensors'), FloatProgress(value=0.0, max=433292294.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f31ea2a9769468aa30137b028b4a122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer_config.json'), FloatProgress(value=0.0, max=59.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d148c8cf7eb4bbaa000c8dc78aea847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='vocab.txt'), FloatProgress(value=0.0, max=213450.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcabdc520c04a79a53edb69d8aa74d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='added_tokens.json'), FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab14d5aae2ea4752ac5fed6f9225c1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='special_tokens_map.json'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama was born in Hawaii and served as the 44th president of the United\n",
      "States.\n",
      "Entities:\n",
      "Barack Obama -> PER\n",
      "Hawaii -> LOC\n",
      "United States -> LOC\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Named Entity Recognition (NER)\n",
    "sentence = \"Barack Obama was born in Hawaii and served as the 44th president of the United States.\"\n",
    "print(\"\\nTask 2: Named Entity Recognition\")\n",
    "ner_model = pipeline('ner', model='dslim/bert-base-NER', grouped_entities=True)\n",
    "ner_result = ner_model(sentence)\n",
    "print(wrapper.fill(sentence))\n",
    "print(\"Entities:\")\n",
    "for entity in ner_result:\n",
    "    print(f\"{entity['word']} -> {entity['entity_group']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 3: Question Answering\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6f625a5779495fbecea6adf4371dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='config.json'), FloatProgress(value=0.0, max=451.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384045c4d5a54213acd576bd9c26d4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='model.safetensors'), FloatProgress(value=0.0, max=265470036.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a19c2263b747869b220c20968e163c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer_config.json'), FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c2f8911c4c424c80b48ec9801da3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='vocab.txt'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66dfccc9c244cd697ea26a5cd7ef90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer.json'), FloatProgress(value=0.0, max=466062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Eiffel Tower was constructed between 1887 and 1889 as the entrance to the\n",
      "1889 World's Fair.  It is located in Paris, France, and stands 324 meters tall.\n",
      "Today, it is one of the most recognizable structures in the world.\n",
      "Question: Where is the Eiffel Tower located?\n",
      "Answer: Paris, France\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Answering a question based on context\n",
    "context = '''\n",
    "The Eiffel Tower was constructed between 1887 and 1889 as the entrance to the 1889 World's Fair. \n",
    "It is located in Paris, France, and stands 324 meters tall. Today, it is one of the most recognizable structures in the world.\n",
    "'''\n",
    "question = \"Where is the Eiffel Tower located?\"\n",
    "print(\"\\nTask 3: Question Answering\")\n",
    "qa_pipeline = pipeline('question-answering', model='distilbert-base-uncased-distilled-squad')\n",
    "answer = qa_pipeline({'question': question, 'context': context})\n",
    "print(wrapper.fill(context))\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 4: Text Summarization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77226d9d640d4c6d94e4fb90c6b98835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='config.json'), FloatProgress(value=0.0, max=1585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62a552ca73d41748fb5186a4c9085cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='model.safetensors'), FloatProgress(value=0.0, max=1625222120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351f35bc374643f58b6af55ef87fb4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='generation_config.json'), FloatProgress(value=0.0, max=363.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0dd1c8aae3491da8cf3f8773b4ae32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='vocab.json'), FloatProgress(value=0.0, max=898823.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2087596b58764ca99b8e112ade870110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='merges.txt'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075590250b7444a5ac70c053fc19a1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer.json'), FloatProgress(value=0.0, max=1355863.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This movie was a roller coaster of emotions. The plot twists kept me on the\n",
      "edge of my seat, and the performances by the cast were stellar. However, the\n",
      "pacing felt slow at times, and the final act seemed a bit rushed. Overall, it\n",
      "was a satisfying experience, but I wished for a more balanced storyline.\n",
      "Summary: The pacing felt slow at times, and the final act seemed a bit rushed. Overall,\n",
      "it was a satisfying experience, but I wished for a more balanced storyline.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Summarizing a long review\n",
    "review = '''\n",
    "This movie was a roller coaster of emotions. The plot twists kept me on the edge of my seat, and the performances by the cast were stellar.\n",
    "However, the pacing felt slow at times, and the final act seemed a bit rushed. Overall, it was a satisfying experience, but I wished for a more balanced storyline.\n",
    "'''\n",
    "print(\"\\nTask 4: Text Summarization\")\n",
    "summarizer = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "summary = summarizer(review, max_length=50, min_length=20, do_sample=False)[0]['summary_text']\n",
    "print(wrapper.fill(review))\n",
    "print(f\"Summary: {wrapper.fill(summary)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 5: Fill in the Blanks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c8d3841b904c4993b295d95580c426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='config.json'), FloatProgress(value=0.0, max=481.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd04d630615469c9405cc9043032ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='model.safetensors'), FloatProgress(value=0.0, max=498818054.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977e99bb2830412489afb6d18610fb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer_config.json'), FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dac9f0b01714e9cbcc56be817eb4dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='vocab.json'), FloatProgress(value=0.0, max=898823.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094d20b607da47208bee2cc26be9e59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='merges.txt'), FloatProgress(value=0.0, max=456318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efe853aa66c4ed6a9787c1bc8bb8a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer.json'), FloatProgress(value=0.0, max=1355863.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: The city is the capital of France.\n",
      "Prediction: The Republic is the capital of France.\n",
      "Prediction: The Paris is the capital of France.\n",
      "Prediction: The capital is the capital of France.\n",
      "Prediction: The Lyon is the capital of France.\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Fill in the blanks (Masked language modeling)\n",
    "masked_sentence = \"The <mask> is the capital of France.\"\n",
    "print(\"\\nTask 5: Fill in the Blanks\")\n",
    "fill_mask_pipeline = pipeline('fill-mask', model='roberta-base')\n",
    "predictions = fill_mask_pipeline(masked_sentence)\n",
    "for prediction in predictions:\n",
    "    print(f\"Prediction: {prediction['sequence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 6: Translation (English to French)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab67c9813544376817c66a41e2a7b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='config.json'), FloatProgress(value=0.0, max=1206.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75835fdf0caa4c8cb97e9e0caa099223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='model.safetensors'), FloatProgress(value=0.0, max=242043056.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db943a8559c4769975024a88f04e241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='generation_config.json'), FloatProgress(value=0.0, max=147.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa882ab8dd8457ca8f04d060f8fe8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer_config.json'), FloatProgress(value=0.0, max=2324.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48e518ab5044ec3b387fe503f56de5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='spiece.model'), FloatProgress(value=0.0, max=791656.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5afa8a4361d747c086a522af1d6c65bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='tokenizer.json'), FloatProgress(value=0.0, max=1389353.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: I love natural language processing.\n",
      "French: J'aime le traitement de la langue naturelle.\n"
     ]
    }
   ],
   "source": [
    "# Task 6: Translation (English to French)\n",
    "english_text = \"I love natural language processing.\"\n",
    "print(\"\\nTask 6: Translation (English to French)\")\n",
    "translator = pipeline('translation_en_to_fr', model='t5-small')\n",
    "french_translation = translator(english_text)\n",
    "print(f\"English: {english_text}\")\n",
    "print(f\"French: {french_translation[0]['translation_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
